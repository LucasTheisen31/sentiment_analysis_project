# ğŸ“Š Scripts e Notebooks - Pipeline de Dados e Treinamento

> DocumentaÃ§Ã£o completa dos scripts utilizados para coleta, limpeza, anÃ¡lise e treinamento do modelo de anÃ¡lise de sentimentos.

---

## ğŸ‘¥ Autoria

**Autor:** Lucas Evandro Theisen  
**Orientador:** Dr. Anderson Brilhador  
**Coorientador:** Dr. Giuvane Conti

**InstituiÃ§Ã£o:** Universidade TecnolÃ³gica Federal do ParanÃ¡ - Campus Santa Helena  
**Curso:** CiÃªncia da ComputaÃ§Ã£o  
**Ano:** 2025

---

## ğŸ“ Estrutura dos Scripts

Esta pasta contÃ©m todos os scripts e notebooks utilizados no desenvolvimento do modelo de anÃ¡lise de sentimentos, organizados por etapa do pipeline:

```
notebooks_and_scripts/
â”‚
â”œâ”€â”€ 01_collection/             # Coleta de dados
â”‚   â””â”€â”€ extraÃ§Ã£o_dos_dados.ipynb
â”‚
â”œâ”€â”€ 02_reannotation/           # ReannotaÃ§Ã£o com Gemini
â”‚   â””â”€â”€ reannotation_gemini_2.5_pro.ipynb
â”‚
â”œâ”€â”€ 03_cleaning/               # Limpeza e prÃ©-processamento
â”‚   â”œâ”€â”€ data_cleaning.ipynb
â”‚   â”œâ”€â”€ data_cleaning_and_filtering_leia.ipynb
â”‚   â””â”€â”€ data_splitting.ipynb
â”‚
â”œâ”€â”€ 04_analysis/               # AnÃ¡lise exploratÃ³ria de dados
â”‚   â””â”€â”€ [seus notebooks aqui]
â”‚
â”œâ”€â”€ 05_training/               # Treinamento do modelo
â”‚   â””â”€â”€ treinamento.ipynb
â”‚
â””â”€â”€ 06_results/                # Resultados e modelos salvos
    â”œâ”€â”€ BERTimbau/
    â”œâ”€â”€ BERT multilingual/
    â””â”€â”€ XLMRoberta/
```

---

## ğŸ”„ Pipeline Completo

### 1ï¸âƒ£ Coleta de Dados (`01_collection/`)

**Objetivo:** Coletar avaliaÃ§Ãµes e comentÃ¡rios em portuguÃªs de diversas fontes.

**Notebooks disponÃ­veis:**
- `extraÃ§Ã£o_dos_dados.ipynb`: Coleta de reviews da Google Play Store usando google-play-scraper

**Funcionalidades:**
- ExtraÃ§Ã£o de reviews de mÃºltiplos apps
- Coleta por nota (1-5 estrelas)
- Diferentes critÃ©rios de ordenaÃ§Ã£o (MOST_RELEVANT, NEWEST)
- ExportaÃ§Ã£o para CSV

**SaÃ­da:** Dataset bruto com textos (content) e notas (score)

---

### 2ï¸âƒ£ ReannotaÃ§Ã£o com Gemini (`02_reannotation/`)

**Objetivo:** Refinar e validar as anotaÃ§Ãµes dos dados usando Gemini API.

**Notebooks disponÃ­veis:**
- `reannotation_gemini_2.5_pro.ipynb`: ReannotaÃ§Ã£o automÃ¡tica usando Gemini 2.5 Pro

**Funcionalidades:**
- ReannotaÃ§Ã£o de avaliaÃ§Ãµes com Gemini API
- Prompt detalhado para classificaÃ§Ã£o 1-5 estrelas
- Modo thinking para melhor raciocÃ­nio
- ValidaÃ§Ã£o e tratamento de erros
- Coluna adicional: `score_reanotado_gemini`

**SaÃ­da:** Dataset com labels refinados e validados pela IA

---

### 3ï¸âƒ£ Limpeza de Dados (`03_cleaning/`)

**Objetivo:** Preprocessar e limpar os dados coletados.

**Abordagens disponÃ­veis:**

**OpÃ§Ã£o 1: Limpeza Simples (demojize)**
- ConversÃ£o de emojis para texto descritivo
- RemoÃ§Ã£o de espaÃ§os duplicados
- NormalizaÃ§Ã£o bÃ¡sica

**OpÃ§Ã£o 2: Limpeza + Filtragem (demojize + LeIA)**
- ConversÃ£o de emojis para texto descritivo
- RemoÃ§Ã£o de espaÃ§os duplicados
- **Filtragem de incoerÃªncias usando LeIA** (remove avaliaÃ§Ãµes onde score e sentimento do texto sÃ£o conflitantes)

**OpÃ§Ã£o 3 (Opcional): DivisÃ£o dos Dados**
- SeparaÃ§Ã£o em treino/validaÃ§Ã£o/teste
- Pode ser feita nesta etapa ou durante o treinamento

**Scripts disponÃ­veis:**
- `data_cleaning.ipynb`: Limpeza bÃ¡sica com demojize
- `data_cleaning_and_filtering_leia.ipynb`: Limpeza + filtragem de incoerÃªncias com LeIA
- `data_splitting.ipynb`: DivisÃ£o opcional dos dados

**SaÃ­da:** Dataset limpo (com ou sem filtragem de incoerÃªncias)

---

### 4ï¸âƒ£ AnÃ¡lise ExploratÃ³ria (`04_analysis/`)

**Objetivo:** Entender os dados atravÃ©s de estatÃ­sticas e visualizaÃ§Ãµes.

**Notebooks disponÃ­veis:**
- Pasta disponÃ­vel para anÃ¡lises exploratÃ³rias futuras

**AnÃ¡lises recomendadas:**
- DistribuiÃ§Ã£o de classes (sentimentos)
- Comprimento dos textos
- Palavras mais frequentes (word clouds)
- AnÃ¡lise de emojis
- CorrelaÃ§Ãµes entre features

**SaÃ­da:** GrÃ¡ficos, estatÃ­sticas e insights sobre os dados

---

### 5ï¸âƒ£ Treinamento (`05_training/`)

**Objetivo:** Treinar e avaliar o modelo BERTimbau.

**Notebooks disponÃ­veis:**
- `treinamento.ipynb`: Notebook completo de treinamento do BERTimbau

**HiperparÃ¢metros utilizados:**
- Batch size: 8
- Learning rate: 3e-5
- Epochs: 10
- Dropout: 0.3
- Weight Decay: 0.01
- Warmup: 10% dos steps
- Scheduler: Linear com warmup

**SaÃ­da:** Modelo treinado e mÃ©tricas de avaliaÃ§Ã£o

---

### 6ï¸âƒ£ Resultados Salvos (`06_results/`)

**Objetivo:** Armazenar modelos treinados e resultados de experimentos.

**ConteÃºdo:**
- `BERTimbau/`: Resultados do modelo BERTimbau
- `BERT multilingual/`: Resultados do modelo BERT multilingual
- `XLMRoberta/`: Resultados do modelo XLM-RoBERTa

**Arquivos salvos:**
- Modelos treinados (.pt, .bin)
- MÃ©tricas de avaliaÃ§Ã£o
- GrÃ¡ficos de treinamento
- Matrizes de confusÃ£o

---

## ğŸš€ Como Usar

### Requisitos

```bash
pip install -r requirements.txt
```

**Principais bibliotecas:**
- google-play-scraper (coleta de dados)
- google-genai, google-generativeai (reannotaÃ§Ã£o com Gemini)
- emoji, leia-br (processamento de texto e filtragem)
- pandas, numpy (manipulaÃ§Ã£o de dados)
- matplotlib, seaborn (visualizaÃ§Ãµes)
- scikit-learn (mÃ©tricas e divisÃ£o de dados)
- torch, transformers (deep learning)
- jupyter, ipykernel (notebooks)

### Executar Pipeline Completo

```bash
# 1. Coletar dados
jupyter notebook 01_collection/extraÃ§Ã£o_dos_dados.ipynb

# 2. Reannotar com Gemini (opcional, mas recomendado)
jupyter notebook 02_reannotation/reannotation_gemini_2.5_pro.ipynb

# 3. Limpar dados (escolha uma abordagem)
# OpÃ§Ã£o A: Limpeza simples
jupyter notebook 03_cleaning/data_cleaning.ipynb
# OpÃ§Ã£o B: Limpeza + filtragem de incoerÃªncias
jupyter notebook 03_cleaning/data_cleaning_and_filtering_leia.ipynb
# OpÃ§Ã£o C (Opcional): Dividir dados
jupyter notebook 03_cleaning/data_splitting.ipynb

# 4. AnÃ¡lise exploratÃ³ria (opcional)
jupyter notebook 04_analysis/eda.ipynb

# 5. Treinar modelo
jupyter notebook 05_training/treinamento.ipynb
```

---

## ğŸ“Š Datasets Utilizados

### Dataset Final

- **Total de exemplos:** [nÃºmero]
- **DistribuiÃ§Ã£o de classes:**
  - Extremamente Negativo: [%]
  - Negativo: [%]
  - Neutro: [%]
  - Positivo: [%]
  - Extremamente Positivo: [%]

- **DivisÃ£o:**
  - Treino: 80%
  - ValidaÃ§Ã£o: 10%
  - Teste: 10%

### Fontes de Dados

[Liste aqui as fontes utilizadas, se pÃºblicas]

---

## ğŸ“ˆ Resultados do Treinamento

### Melhores HiperparÃ¢metros

```python
{
    "learning_rate": 3e-5,
    "batch_size": 8,
    "epochs": 10,
    "dropout": 0.3,
    "weight_decay": 0.01,
    "warmup_steps": 10%
}
```

### MÃ©tricas no Conjunto de Teste

| MÃ©trica | Valor |
|---------|-------|
| AcurÃ¡cia | [%] |
| F1-Score (macro) | [score] |
| PrecisÃ£o | [%] |
| Recall | [%] |

---

## ğŸ”§ Reprodutibilidade

### Seeds Utilizadas

Para garantir reprodutibilidade, as seguintes seeds foram fixadas:

```python
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
```

### Ambiente

- **Python:** 3.9+
- **PyTorch:** 2.0+
- **Transformers:** 4.30+
- **CUDA:** 11.8+ (opcional, para GPU)

---

## ğŸ“ Notas Importantes

1. **Dados SensÃ­veis:** Certifique-se de que nenhum dado sensÃ­vel ou proprietÃ¡rio foi incluÃ­do nos scripts.

2. **Licenciamento:** Todos os scripts estÃ£o sob licenÃ§a MIT (veja arquivo LICENSE na raiz).

3. **CitaÃ§Ã£o de Datasets:** Se utilizou datasets pÃºblicos, cite-os adequadamente nos scripts.

4. **Ã‰tica:** Respeite os termos de uso das fontes de dados e robots.txt ao fazer scraping.

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **README.txt** (raiz): InstruÃ§Ãµes de uso do sistema completo
- **api/README.md**: DocumentaÃ§Ã£o tÃ©cnica da API
- **api/TRAINING.md**: ExplicaÃ§Ã£o visual dos conceitos de treinamento

---

## ğŸ“§ Contato

Para dÃºvidas sobre os scripts e metodologia:

**Lucas Evandro Theisen**  
[seu-email@exemplo.com]

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob:
- **CÃ³digo:** MIT License
- **Trabalho AcadÃªmico:** Creative Commons BY 4.0

Veja o arquivo `LICENSE` na raiz do projeto para mais detalhes.

---

**Nota:** Esta documentaÃ§Ã£o faz parte do TCC "Sistema de AnÃ¡lise de Sentimentos para AvaliaÃ§Ãµes em PortuguÃªs Brasileiro Utilizando Deep Learning", desenvolvido na UTFPR - Campus Santa Helena.
