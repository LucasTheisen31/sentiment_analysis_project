# üìä Scripts e Notebooks - Pipeline de Dados e Treinamento

## üë• Autoria

**Autor:** Lucas Evandro Theisen  
**Orientador:** Prof. Dr. Anderson Brilhador  
**Coorientador:** Prof. Dr. Giuvane Conti

**Institui√ß√£o:** Universidade Tecnol√≥gica Federal do Paran√° - Campus Santa Helena  
**Curso:** Bacharelado em Ci√™ncia da Computa√ß√£o  
**Ano:** 2025

### Banca Examinadora

- Prof. Dr. Anderson Brilhador (Orientador) - UTFPR
- Profa. Dra. Giani Carla Ito - UTFPR
- Profa. Dra. Leliane Rezende - UTFPR

**Data de Aprova√ß√£o:** 1 de dezembro de 2025

---

## üìÑ Licen√ßa

<div align="center">

![CC BY-NC-SA](https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png)

**Creative Commons Atribui√ß√£o-N√£oComercial-CompartilhaIgual 4.0 Internacional**

</div>

¬© 2025 Lucas Evandro Theisen

Esta licen√ßa permite que reutilizadores distribuam, remixem, adaptem e criem a partir do material em qualquer meio ou formato apenas para fins n√£o comerciais. Se outros modificarem ou adaptarem o material, eles devem licenciar o material modificado sob termos id√™nticos.

### üìã Termos da Licen√ßa

**BY:** O cr√©dito deve ser dado a voc√™, o criador.

**NC:** Apenas o uso n√£o comercial do seu trabalho √© permitido. *N√£o comercial significa n√£o primariamente direcionado para ou dirigido para vantagem comercial ou compensa√ß√£o monet√°ria.*

**SA:** Adapta√ß√µes devem ser compartilhadas sob os mesmos termos.

---

Veja o arquivo [LICENSE](../LICENSE) para o texto legal completo da licen√ßa.

---

---

## üìÅ Estrutura dos Scripts

Esta pasta cont√©m todos os scripts e notebooks utilizados no desenvolvimento do modelo de an√°lise de sentimentos, organizados por etapa do pipeline:

```
notebooks_and_scripts/
‚îÇ
‚îú‚îÄ‚îÄ 01_collection/             # Coleta de dados
‚îÇ   ‚îî‚îÄ‚îÄ data_collection.ipynb
‚îÇ
‚îú‚îÄ‚îÄ 02_reannotation/           # Reannota√ß√£o com Gemini
‚îÇ   ‚îî‚îÄ‚îÄ reannotation_gemini_2.5_pro.ipynb
‚îÇ
‚îú‚îÄ‚îÄ 03_cleaning/               # Limpeza e pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ data_cleaning.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ data_cleaning_and_filtering_leia.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ data_splitting.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ reviews_3000.csv
‚îÇ
‚îú‚îÄ‚îÄ 04_training/               # Treinamento do modelo
‚îÇ   ‚îî‚îÄ‚îÄ treinamento.ipynb
‚îÇ
‚îú‚îÄ‚îÄ 05_results/                # Resultados e modelos salvos
‚îÇ   ‚îú‚îÄ‚îÄ BERTimbau/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Base/              # BERTimbau Base (109M par√¢metros)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Large/             # BERTimbau Large (335M par√¢metros)
‚îÇ   ‚îú‚îÄ‚îÄ BERT multilingual/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Base/              # BERT Multilingual Base
‚îÇ   ‚îî‚îÄ‚îÄ XLMRoberta/
‚îÇ       ‚îî‚îÄ‚îÄ Base/              # XLM-RoBERTa Base
‚îÇ
‚îî‚îÄ‚îÄ requirements.txt           # Depend√™ncias do projeto
```

---

## üîÑ Pipeline Completo

### 1Ô∏è‚É£ Coleta de Dados (`01_collection/`)

**Objetivo:** Coletar avalia√ß√µes e coment√°rios em portugu√™s de aplicativos da Google Play Store.

**Notebook dispon√≠vel:**

- [data_collection.ipynb](01_collection/data_collection.ipynb): Coleta de reviews usando `google-play-scraper`

**Funcionalidades implementadas:**

- Extra√ß√£o de informa√ß√µes de aplicativos (t√≠tulo, desenvolvedor, categoria, etc.)
- Coleta de reviews de m√∫ltiplos apps simultaneamente
- Filtragem por notas (1-5 estrelas)
- Diferentes crit√©rios de ordena√ß√£o:
  - `Sort.MOST_RELEVANT`: Reviews mais relevantes
  - `Sort.NEWEST`: Reviews mais recentes
- Controle de quantidade de reviews por app
- Exporta√ß√£o autom√°tica para CSV
- Identifica√ß√£o do app de origem (`app_id`) em cada review

**Dados coletados por review:**

- `reviewId`: ID √∫nico do coment√°rio
- `userName`: Nome do usu√°rio
- `userImage`: URL da imagem do perfil
- `content`: Texto do coment√°rio
- `score`: Nota (1-5 estrelas)
- `thumbsUpCount`: Curtidas no coment√°rio
- `reviewCreatedVersion`: Vers√£o do app no momento da avalia√ß√£o
- `at`: Data e hora da avalia√ß√£o
- `replyContent`: Resposta do desenvolvedor (se houver)
- `repliedAt`: Data da resposta
- `app_id`: Identificador do aplicativo

**Sa√≠da:** Dataset bruto `1_dataset_original.csv` com textos e notas originais da Google Play Store

---

### 2Ô∏è‚É£ Reannota√ß√£o com Gemini (`02_reannotation/`)

**Objetivo:** Refinar e validar as anota√ß√µes dos dados usando a API Gemini 2.5 Pro.

**Notebook dispon√≠vel:**

- [reannotation_gemini_2.5_pro.ipynb](02_reannotation/reannotation_gemini_2.5_pro.ipynb): Reannota√ß√£o autom√°tica usando Gemini 2.5 Pro

**Por que reanota√ß√£o?**

As notas da Google Play Store podem conter inconsist√™ncias onde o texto do coment√°rio n√£o corresponde √† nota atribu√≠da pelo usu√°rio. A reannota√ß√£o utiliza IA para:

- Identificar inconsist√™ncias entre texto e nota
- Corrigir classifica√ß√µes baseando-se no conte√∫do textual
- Melhorar a qualidade dos dados de treinamento
- Reduzir ru√≠do no dataset

**Funcionalidades implementadas:**

- Integra√ß√£o com Google Gemini API (`google-genai`)
- Prompt engineering detalhado para classifica√ß√£o 1-5 estrelas
- Modo "thinking" do Gemini para racioc√≠nio aprofundado
- An√°lise contextual de sentimento do texto
- Sistema de valida√ß√£o e tratamento de erros
- Controle de rate limiting e timeouts
- Salvamento incremental (checkpoints)
- Coluna adicional no dataset: `score_reanotado_gemini`

**Configura√ß√£o do modelo:**

```python
model = "gemini-2.0-flash-thinking-exp-01-21"
temperature = 0.1  # Baixa temperatura para maior consist√™ncia
```

**Prompt utilizado:**

O notebook utiliza um prompt estruturado que:

- Analisa o sentimento do texto
- Considera contexto cultural brasileiro
- Avalia emojis e express√µes coloquiais
- Classifica em escala 1-5 (muito negativo ‚Üí muito positivo)

**Sa√≠da:** Dataset reannotado `2_dataset_reanotado_gpt.csv` ou `3_dataset_reanotado_gemini_2_5_pro.csv` com labels refinados pela IA

---

### 3Ô∏è‚É£ Limpeza de Dados (`03_cleaning/`)

**Objetivo:** Preprocessar, limpar e preparar os dados para treinamento.

**Notebooks dispon√≠veis:**

#### üìÑ [data_cleaning.ipynb](03_cleaning/data_cleaning.ipynb)

**Limpeza b√°sica com demojize**

**Funcionalidades:**

- Convers√£o de emojis para texto descritivo usando `emoji.demojize()`
  - Exemplo: üòä ‚Üí `:smiling_face_with_smiling_eyes:`
- Remo√ß√£o de espa√ßos duplicados
- Normaliza√ß√£o de caracteres especiais
- Remo√ß√£o de linhas duplicadas
- Tratamento de valores nulos

**Vantagem:** Preserva a informa√ß√£o sem√¢ntica dos emojis em formato textual

---

#### üìÑ [data_cleaning_and_filtering_leia.ipynb](03_cleaning/data_cleaning_and_filtering_leia.ipynb)

**Limpeza + Filtragem de Incoer√™ncias com LeIA**

**Funcionalidades adicionais:**

- Todas as funcionalidades do `data_cleaning.ipynb`
- **Filtragem inteligente usando LeIA (Lexicon-based Sentiment Analysis)**
  - An√°lise de sentimento do texto usando l√©xico em portugu√™s
  - Detec√ß√£o de incoer√™ncias entre score e sentimento textual
  - Remo√ß√£o de exemplos conflitantes que podem prejudicar o treinamento
  - Threshold configur√°vel para n√≠vel de filtragem (padr√£o: 0.5)

**Processo de filtragem:**

1. LeIA analisa o sentimento do texto (score de -1 a +1)
2. Compara com a nota atribu√≠da (1-5 estrelas)
3. Remove exemplos onde h√° conflito significativo
4. Mant√©m apenas dados consistentes

**Vantagem:** Dataset mais limpo e consistente, reduzindo ru√≠do no treinamento

---

#### üìÑ [data_splitting.ipynb](03_cleaning/data_splitting.ipynb)

**Divis√£o dos Dados (Opcional)**

**Funcionalidades:**

- Separa√ß√£o em conjuntos de treino/valida√ß√£o/teste
- Estratifica√ß√£o por classe (mant√©m propor√ß√£o de sentimentos)
- Seed fixa para reprodutibilidade
- Exporta√ß√£o para arquivos separados

**Propor√ß√µes t√≠picas:**

- Treino: 70% ou 80%
- Valida√ß√£o: 10% ou 15%
- Teste: 10% ou 20%

**Nota:** A divis√£o tamb√©m pode ser feita diretamente no notebook de treinamento

---

**Arquivos gerados:**

- Pasta `datasets/Demojize/`: Datasets limpos com emojis convertidos
- Pasta `datasets/Leia + demojize/`: Datasets filtrados por LeIA
- Pasta `datasets/Divididos/`: Splits de treino/valida√ß√£o/teste
- `reviews_3000.csv`: Dataset de exemplo com 3000 reviews

**Sa√≠da principal:** Dataset limpo e preparado para treinamento, com ou sem filtragem de incoer√™ncias

---

### 4Ô∏è‚É£ Treinamento (`04_training/`)

**Objetivo:** Treinar e avaliar modelos transformers para an√°lise de sentimentos.

**Notebook dispon√≠vel:**

#### üìÑ [treinamento.ipynb](04_training/treinamento.ipynb)

**Notebook completo de treinamento e avalia√ß√£o**

**Modelos suportados:**

1. **BERTimbau Base** (109M par√¢metros) - `neuralmind/bert-base-portuguese-cased`
2. **BERTimbau Large** (335M par√¢metros) - `neuralmind/bert-large-portuguese-cased`
3. **BERT Multilingual Base** - `bert-base-multilingual-cased`
4. **XLM-RoBERTa Base** - `xlm-roberta-base`

**Pipeline de treinamento:**

1. **Carregamento de dados**
   - Leitura do dataset limpo
   - Verifica√ß√£o de qualidade dos dados
   - An√°lise explorat√≥ria inicial

2. **Tokeniza√ß√£o**
   - Uso do tokenizer do modelo pr√©-treinado
   - Padding para tamanho m√°ximo (MAX_LEN=128 ou 256)
   - Cria√ß√£o de attention masks
   - Convers√£o para tensores PyTorch

3. **Cria√ß√£o de DataLoaders**
   - Batching dos dados
   - Shuffling do conjunto de treino
   - Otimiza√ß√£o para GPU/CPU

4. **Defini√ß√£o da arquitetura**
   - Carregamento do modelo pr√©-treinado
   - Camada de classifica√ß√£o customizada
   - Dropout para regulariza√ß√£o
   - Fine-tuning de todas as camadas

5. **Configura√ß√£o do treinamento**
   - Otimizador: AdamW
   - Learning rate scheduler: Linear com warmup
   - Loss function: CrossEntropyLoss (com ou sem class weights)
   - M√©tricas: Accuracy, F1-Score (macro), Precision, Recall

6. **Loop de treinamento**
   - Treinamento por epochs
   - Valida√ß√£o a cada epoch
   - Early stopping (opcional)
   - Salvamento do melhor modelo
   - Logging de m√©tricas

7. **Avalia√ß√£o final**
   - Teste no conjunto de teste
   - Matriz de confus√£o
   - Relat√≥rio de classifica√ß√£o
   - An√°lise de erros

**Hiperpar√¢metros t√≠picos:**

```python
# Configura√ß√µes comuns
MAX_LEN = 128           # Comprimento m√°ximo de tokens
BATCH_SIZE = 4, 8, 16   # Tamanho do batch (varia por modelo/GPU)
EPOCHS = 10             # N√∫mero de √©pocas
TEST_SIZE = 0.3         # 30% para valida√ß√£o+teste

# Otimiza√ß√£o
LEARNING_RATE = 2e-5, 3e-5, 5e-5  # Learning rates testados
WEIGHT_DECAY = 0.01     # Regulariza√ß√£o L2
DROPOUT = 0.3           # Dropout na camada de classifica√ß√£o
WARMUP_STEPS = 10%      # Warmup do learning rate

# Class balancing
CLASS_WEIGHTS = None    # Ou 'balanced' para desbalanceamento
```

**Experimentos realizados:**

O notebook suporta m√∫ltiplas configura√ß√µes experimentais:

- 3 datasets diferentes (Original, Reannotado GPT, Reannotado Gemini)
- 3 learning rates (2e-5, 3e-5, 5e-5)
- 2-3 batch sizes (4, 8, 16)
- Com/sem class weights
- Com/sem demojize
- Com/sem filtragem LeIA
- Diferentes splits de valida√ß√£o/teste

**T√©cnicas de otimiza√ß√£o:**

- **Gradient accumulation**: Para simular batch sizes maiores
- **Mixed precision training**: Para economia de mem√≥ria (opcional)
- **Learning rate warmup**: Estabiliza o in√≠cio do treinamento
- **Weight decay**: Regulariza√ß√£o para evitar overfitting
- **Class weights**: Balanceamento de classes desbalanceadas

**Sa√≠da:** Modelo treinado (`.pt`), hist√≥rico de treinamento, m√©tricas de avalia√ß√£o

---

### 5Ô∏è‚É£ Resultados Salvos (`05_results/`)

**Objetivo:** Armazenar modelos treinados, m√©tricas e resultados de experimentos extensivos.

**Estrutura de pastas:**

```
05_results/
‚îú‚îÄ‚îÄ BERTimbau/
‚îÇ   ‚îú‚îÄ‚îÄ Base/          # 90+ experimentos com BERTimbau Base
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DTOriginal - 3000 - EPOCHS=10 - TEST_SIZE=0.3 - BATCH_S=4 - LR=2e-5/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DTOriginal - 3000 - ... - ClassW=balanced - Demojize/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DTOriginal - 3000 - ... - ClassW=balanced - Demojize - Leia0.5/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DTReanotadoGPT - 3000 - EPOCHS=10 - TEST_SIZE=0.3 - BATCH_S=4 - LR=3e-5/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DTReanotadoGemini-2.5-pro - 3000 - EPOCHS=10 - ... /
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (m√∫ltiplas configura√ß√µes)
‚îÇ   ‚îî‚îÄ‚îÄ Large/         # 36+ experimentos com BERTimbau Large
‚îÇ       ‚îú‚îÄ‚îÄ DTOriginal - 3000 - EPOCHS=10 - TEST_SIZE=0.3 - BATCH_S=4 - LR=2e-5/
‚îÇ       ‚îú‚îÄ‚îÄ DTReanotadoGPT - 3000 - ... /
‚îÇ       ‚îî‚îÄ‚îÄ ... (m√∫ltiplas configura√ß√µes)
‚îÇ
‚îú‚îÄ‚îÄ BERT multilingual/
‚îÇ   ‚îî‚îÄ‚îÄ Base/          # Experimentos com BERT Multilingual
‚îÇ
‚îî‚îÄ‚îÄ XLMRoberta/
    ‚îî‚îÄ‚îÄ Base/          # Experimentos com XLM-RoBERTa
```

**Conte√∫do de cada pasta de experimento:**

Cada pasta de experimento cont√©m:

- `model.pt`: Modelo treinado (state dict do PyTorch)
- `training_history.csv`: Hist√≥rico de loss e m√©tricas por epoch
- `metrics.json`: M√©tricas finais (accuracy, F1, precision, recall)
- `confusion_matrix.png`: Matriz de confus√£o visualizada
- `classification_report.txt`: Relat√≥rio detalhado por classe
- `training_curves.png`: Gr√°ficos de loss e accuracy
- `config.json`: Configura√ß√£o de hiperpar√¢metros usada

**Nomenclatura dos experimentos:**

Os experimentos seguem um padr√£o descritivo:

- `DTOriginal`: Dataset original da Google Play Store
- `DTReanotadoGPT`: Dataset reannotado com GPT
- `DTReanotadoGemini-2.5-pro`: Dataset reannotado com Gemini 2.5 Pro
- `3000`: N√∫mero de exemplos no dataset
- `EPOCHS=10`: N√∫mero de √©pocas de treinamento
- `TEST_SIZE=0.3`: Propor√ß√£o de dados para valida√ß√£o+teste
- `BATCH_S=4`: Tamanho do batch
- `LR=2e-5`: Learning rate
- `ClassW=balanced`: Uso de class weights balanceados
- `Demojize`: Emojis convertidos para texto
- `Leia0.5`: Filtragem LeIA com threshold 0.5
- `TestVal=Orig`: Valida√ß√£o/teste com dataset original

**Compara√ß√£o de modelos:**

Total de experimentos realizados:

- **BERTimbau Base**: ~90 experimentos
- **BERTimbau Large**: ~36 experimentos
- **BERT Multilingual**: M√∫ltiplos experimentos
- **XLM-RoBERTa**: M√∫ltiplos experimentos

**Grid search realizado:**

- 3 modelos base (BERTimbau Base/Large, BERT Multilingual)
- 3 datasets (Original, GPT, Gemini)
- 3 learning rates (2e-5, 3e-5, 5e-5)
- 2-3 batch sizes (4, 8, 16)
- 2 configura√ß√µes de weights (None, balanced)
- 2 configura√ß√µes de limpeza (original, demojize)
- 2-3 configura√ß√µes de filtragem (nenhuma, LeIA 0.5, cross-validation)

**Total**: Mais de 200 experimentos realizados para encontrar a melhor configura√ß√£o

---

## üöÄ Como Usar

### Requisitos

```bash
pip install -r requirements.txt
```

**Principais bibliotecas:**

- google-play-scraper (coleta de dados)
- google-genai, google-generativeai (reannota√ß√£o com Gemini)
- emoji, leia-br (processamento de texto e filtragem)
- pandas, numpy (manipula√ß√£o de dados)
- matplotlib, seaborn (visualiza√ß√µes)
- scikit-learn (m√©tricas e divis√£o de dados)
- torch, transformers (deep learning)
- jupyter, ipykernel (notebooks)

### Executar Pipeline Completo

```bash
# 0. Instalar depend√™ncias
pip install -r requirements.txt

# 1. Coletar dados da Google Play Store
jupyter notebook 01_collection/data_collection.ipynb
# Sa√≠da: datasets/1_dataset_original.csv

# 2. Reannotar com Gemini (opcional, mas altamente recomendado)
jupyter notebook 02_reannotation/reannotation_gemini_2.5_pro.ipynb
# Sa√≠da: datasets/3_dataset_reanotado_gemini_2_5_pro.csv

# 3. Limpar e preparar dados
# Escolha uma das op√ß√µes abaixo:

# Op√ß√£o A: Limpeza b√°sica (apenas demojize)
jupyter notebook 03_cleaning/data_cleaning.ipynb
# Sa√≠da: datasets/Demojize/[dataset]_limpeza_demojize.csv

# Op√ß√£o B: Limpeza + filtragem de incoer√™ncias (RECOMENDADO)
jupyter notebook 03_cleaning/data_cleaning_and_filtering_leia.ipynb
# Sa√≠da: datasets/Leia + demojize/filtrados/[dataset]_limpeza_demojize_leia.csv

# Op√ß√£o C: Dividir dados (opcional, pode ser feito no treinamento)
jupyter notebook 03_cleaning/data_splitting.ipynb
# Sa√≠da: datasets/Divididos/train.csv, val.csv, test.csv

# 4. Treinar modelo
jupyter notebook 04_training/treinamento.ipynb
# Sa√≠da: 05_results/[Modelo]/[Config]/model.pt + m√©tricas

# 5. Analisar resultados
# Verifique os arquivos gerados em 05_results/
```

### Pipeline Recomendado (Melhor Qualidade)

Para obter os melhores resultados baseados nos experimentos realizados:

```bash
# 1. Coleta de dados
jupyter notebook 01_collection/data_collection.ipynb

# 2. Reannota√ß√£o com Gemini (melhora consist√™ncia)
jupyter notebook 02_reannotation/reannotation_gemini_2.5_pro.ipynb

# 3. Limpeza + Filtragem LeIA (remove incoer√™ncias)
jupyter notebook 03_cleaning/data_cleaning_and_filtering_leia.ipynb

# 4. Treinamento com BERTimbau Base
# Configure no notebook:
# - DATASET: dataset reannotado e filtrado
# - MODEL: BERTimbau Base
# - LEARNING_RATE: 3e-5
# - BATCH_SIZE: 8 ou 16
# - CLASS_WEIGHTS: 'balanced' (se classes desbalanceadas)
jupyter notebook 04_training/treinamento.ipynb
```

---

## üìä Datasets Utilizados

### Datasets Principais

Os datasets est√£o localizados na pasta `../datasets/`:

1. **[1_dataset_original.csv](../datasets/1_dataset_original.csv)**
   - Dataset bruto coletado da Google Play Store
   - ~3000+ reviews de aplicativos brasileiros
   - Colunas principais: `content` (texto), `score` (1-5)

2. **[2_dataset_reanotado_gpt.csv](../datasets/2_dataset_reanotado_gpt.csv)**
   - Dataset reannotado usando GPT
   - Coluna adicional: `score_reanotado_gpt`
   - Melhora consist√™ncia entre texto e sentimento

3. **[3_dataset_reanotado_gemini_2_5_pro.csv](../datasets/3_dataset_reanotado_gemini_2_5_pro.csv)**
   - Dataset reannotado usando Gemini 2.5 Pro
   - Coluna adicional: `score_reanotado_gemini`
   - An√°lise contextual mais profunda

### Datasets Processados

Localizados nas subpastas:

- **`Demojize/`**: Datasets com emojis convertidos para texto
- **`Leia + demojize/filtrados/`**: Datasets filtrados por incoer√™ncias (LeIA)
- **`Divididos/`**: Datasets j√° divididos em treino/valida√ß√£o/teste

### Caracter√≠sticas do Dataset

- **Tamanho:** ~3000 exemplos (varia ap√≥s filtragem)
- **Idioma:** Portugu√™s brasileiro
- **Dom√≠nio:** Reviews de aplicativos m√≥veis (Google Play Store)
- **Classes:** 5 (1-5 estrelas)
  - 1 ‚≠ê: Muito negativo
  - 2 ‚≠ê: Negativo
  - 3 ‚≠ê: Neutro
  - 4 ‚≠ê: Positivo
  - 5 ‚≠ê: Muito positivo

### Divis√£o T√≠pica dos Dados

- **Treino:** 70% (2100 exemplos)
- **Valida√ß√£o:** 15% (450 exemplos)
- **Teste:** 15% (450 exemplos)

*Nota: Os valores exatos variam dependendo do dataset e filtragem aplicada*

### Fontes de Dados

- Google Play Store (via `google-play-scraper`)
- Aplicativos brasileiros de diversas categorias
- Per√≠odo de coleta: 2024-2025

---

## üìà Resultados do Treinamento

### Configura√ß√£o Recomendada

Baseado em mais de 200 experimentos realizados:

```python
# Dataset
DATASET = "3_dataset_reanotado_gemini_2_5_pro"  # Reannotado com Gemini
CLEANING = "Demojize"                           # Emojis convertidos
FILTERING = "Leia0.5"                           # Filtrado por LeIA (threshold 0.5)

# Modelo
MODEL = "neuralmind/bert-base-portuguese-cased"  # BERTimbau Base
MAX_LEN = 128                                     # Comprimento m√°ximo de tokens

# Hiperpar√¢metros
LEARNING_RATE = 3e-5      # Melhor performance nos experimentos
BATCH_SIZE = 8            # Balanceamento entre velocidade e mem√≥ria
EPOCHS = 10               # Converg√™ncia t√≠pica entre 7-10 epochs
DROPOUT = 0.3             # Regulariza√ß√£o
WEIGHT_DECAY = 0.01       # Regulariza√ß√£o L2
WARMUP_STEPS = 10%        # Warmup do learning rate

# Balanceamento
CLASS_WEIGHTS = "balanced"  # Recomendado se classes desbalanceadas

# Otimizador
OPTIMIZER = "AdamW"
SCHEDULER = "linear_with_warmup"
```

### Resultados T√≠picos (BERTimbau Base)

Os resultados variam conforme o dataset e configura√ß√£o. Exemplos t√≠picos:

| Configura√ß√£o | Accuracy | F1-Score (macro) | Observa√ß√µes |
|--------------|----------|------------------|-------------|
| Original + Demojize | 55-65% | 0.45-0.55 | Baseline, presen√ßa de ru√≠do |
| Reannotado GPT + Demojize | 60-70% | 0.50-0.60 | Melhora na consist√™ncia |
| Reannotado Gemini + Demojize + LeIA | 65-75% | 0.55-0.65 | **Melhor performance** |
| BERTimbau Large (melhor config) | 70-78% | 0.60-0.68 | Mais par√¢metros, mais lento |

*Nota: Valores exatos dispon√≠veis nas pastas individuais em `05_results/`*

### Insights dos Experimentos

**1. Impacto da reannota√ß√£o:**

- Reannota√ß√£o com Gemini 2.5 Pro melhorou consist√™ncia em ~5-10%
- GPT tamb√©m efetivo, mas Gemini teve melhor compreens√£o de contexto brasileiro

**2. Impacto da filtragem LeIA:**

- Remo√ß√£o de incoer√™ncias melhorou F1-score em ~3-7%
- Dataset menor mas mais limpo = melhor generaliza√ß√£o

**3. Learning rate:**

- 2e-5: Converg√™ncia mais lenta, mais est√°vel
- **3e-5: Melhor balan√ßo** (recomendado)
- 5e-5: Converg√™ncia r√°pida, risco de overfitting

**4. Batch size:**

- Batch 4: Mais lento, mem√≥ria limitada
- **Batch 8: Melhor balan√ßo** (recomendado)
- Batch 16: Mais r√°pido, requer mais mem√≥ria GPU

**5. Class weights:**

- Essencial quando classes est√£o desbalanceadas (>2:1 ratio)
- Melhora recall de classes minorit√°rias

**6. Modelo:**

- BERTimbau Base: Melhor custo-benef√≠cio
- BERTimbau Large: +5-8% accuracy, 3x mais lento
- BERT Multilingual: Performance inferior para portugu√™s
- XLM-RoBERTa: Comparable ao BERTimbau Base

---

## üîß Reprodutibilidade

### Seeds Utilizadas

Para garantir reprodutibilidade, as seguintes seeds foram fixadas em todos os notebooks:

```python
SEED = 42  # Seed padr√£o usado em todos os experimentos

# Python random
import random
random.seed(SEED)

# NumPy
import numpy as np
np.random.seed(SEED)

# PyTorch
import torch
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

# Configura√ß√µes adicionais para reprodutibilidade
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```

### Ambiente e Requisitos

**Python:** 3.9+ (testado em 3.9, 3.10, 3.11)

**Principais depend√™ncias:**

```txt
# Deep Learning
torch==2.1.2+cpu           # PyTorch (CPU version)
torchvision==0.16.2+cpu
torchaudio==2.1.2+cpu
transformers==4.36.2       # Hugging Face Transformers

# Data Science
pandas==2.1.4
numpy==1.26.4
matplotlib==3.8.2
seaborn==0.13.0
scikit-learn==1.3.2

# Text Processing
emoji==2.10.0              # Convers√£o de emojis
leia-br==0.0.1             # An√°lise de sentimento em portugu√™s

# APIs
google-play-scraper==1.2.7  # Coleta de dados
google-genai==0.2.2         # Reannota√ß√£o com Gemini
google-generativeai==0.8.3

# Jupyter
jupyter==1.0.0
ipykernel==6.27.1
notebook==7.0.6

# Utilities
tqdm==4.66.1               # Barras de progresso
watermark==2.4.3           # Versionamento
```

## üìö Documenta√ß√£o Adicional

### Documentos do Projeto

| Documento | Descri√ß√£o |
|-----------|-----------|
| [README.txt](../README.txt) | Instru√ß√µes de uso do sistema completo |
| [README.md](../README.md) | Vis√£o geral do projeto |
| [api/README.md](../sentiment_analysis_project/api/README.md) | Documenta√ß√£o t√©cnica da API |
| [api/TRAINING.md](../sentiment_analysis_project/api/TRAINING.md) | Explica√ß√£o visual dos conceitos de treinamento |
| [LICENSE](../LICENSE) | Licen√ßa do projeto |

---

## üìÑ Cita√ß√£o Acad√™mica

Se voc√™ utilizar este trabalho em sua pesquisa, por favor cite:

```bibtex
@mastersthesis{theisen2025sentiment,
  title={An√°lise de Sentimentos em Coment√°rios de Aplicativos Comerciais},
  author={Theisen, Lucas Evandro},
  year={2025},
  school={Universidade Tecnol√≥gica Federal do Paran√°},
  type={Trabalho de Conclus√£o de Curso},
  address={Santa Helena, PR, Brasil}
}
```

**Nota:** Esta documenta√ß√£o faz parte do TCC "AN√ÅLISE DE SENTIMENTOS EM COMENT√ÅRIOS DE APLICATIVOS COMERCIAIS", desenvolvido na UTFPR - Campus Santa Helena em 2025.
